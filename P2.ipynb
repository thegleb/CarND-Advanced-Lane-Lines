{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "import time\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First here's some calibration code (mostly from the sample code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_calibration(img_list):\n",
    "    \"\"\"\n",
    "    Returns some calibrated points based on a list of images\n",
    "    \"\"\"\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    for fname in img_list:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    return (objpoints, imgpoints)\n",
    "\n",
    "# Make a list of calibration images\n",
    "calibration_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# global calibration values\n",
    "objpoints, imgpoints = get_calibration(calibration_images)\n",
    "target_dimensions = (720, 1280)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, target_dimensions, None, None)\n",
    "\n",
    "# nx, ny values to use for undistorting\n",
    "max_points = np.max(objpoints[0], axis=0) + 1\n",
    "nx = int(max_points[0])\n",
    "ny = int(max_points[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper methods we will be using for debug output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    \"\"\"\n",
    "    Creates a plot and displays an image on it\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize = (18,10))\n",
    "    axes = figure.add_subplot(111)\n",
    "\n",
    "    is_grayscale = len(img) != 3\n",
    "    if is_grayscale is True:\n",
    "        axes.imshow(img, cmap='gray', aspect='auto', interpolation='nearest') \n",
    "    else:\n",
    "        axes.imshow(img, aspect='auto', interpolation='nearest') \n",
    "\n",
    "def make_3_channel_image_from_binary_channel(bin_channel):\n",
    "    \"\"\"\n",
    "    Takes a single-channel binary image (1s and 0s) and triples the channels\n",
    "    \"\"\"\n",
    "    return np.dstack((bin_channel, bin_channel, bin_channel)) * 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method for compositing the final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(bottom_image, top_image, bottom_image_opacity=1, top_image_opacity=0.6, γ=0.):\n",
    "    \"\"\"\n",
    "    Overlays a couple images on each other\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(bottom_image, bottom_image_opacity, top_image, top_image_opacity, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few methods for finding lane line pixels either from a prior lane line representation or a sliding window rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pixels_in_window(nonzero, bounds):\n",
    "    \"\"\"\n",
    "    Given a rectangular window and a binary image, find all the non-zero pixels inside the window\n",
    "    \"\"\"\n",
    "    nonzeroy, nonzerox = nonzero\n",
    "    min_x, max_x, min_y, max_y = bounds\n",
    "    return ((nonzeroy >= min_y) & (nonzeroy < max_y) & (nonzerox >= min_x) &  (nonzerox < max_x)).nonzero()[0]\n",
    "\n",
    "def get_x_from_poly(fit_fn, y):\n",
    "    \"\"\"\n",
    "    Given a polynomial function (quadratic in this case) and a y value, get the x value\n",
    "    (We draw the parabola \"sideways\" in the image to represent the lane line)\n",
    "    \"\"\"\n",
    "\n",
    "    a, b, c = fit_fn\n",
    "    return a * y ** 2 + b * y + c\n",
    "\n",
    "def get_pixels_from_prior(nonzero, prior_fit_fn, margin, height):\n",
    "    \"\"\"\n",
    "    Given a binary window, a prior polynomial function, and a max y,\n",
    "    find all pixels within a certain horizontal margin\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    nonzeroy, nonzerox = nonzero\n",
    "    for i in range(height):\n",
    "        x = get_x_from_poly(prior_fit_fn, i)\n",
    "        min_x = x - margin\n",
    "        max_x = x + margin\n",
    "        ((i == nonzeroy) & (nonzerox >= min_x) & (nonzerox < max_x)).nonzero()\n",
    "        result.extend(((i == nonzeroy) & (nonzerox >= min_x) & (nonzerox < max_x)).nonzero()[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few methods for finding and drawing lane lines on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane_on_image(new_image, left_line, right_line):\n",
    "    \"\"\"\n",
    "    This method draws 3 things: left lane line, right lane line, and a polygon representation of the lane\n",
    "    \"\"\"\n",
    "    left_x, left_y = left_line.get_x_and_y()\n",
    "    right_x, right_y = right_line.get_x_and_y()\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_x, left_y]))]) if len(left_x) > 0 and len(left_y) > 0 else []\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_x, right_y])))]) if len(right_x) > 0 and len(right_y) > 0 else []\n",
    "\n",
    "    if len(left_x) > 0 and len(right_x) > 0:\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        cv2.fillPoly(new_image, np.int_([pts]), (255, 255, 0))\n",
    "\n",
    "    cv2.polylines(new_image, np.int32([pts_left]), 0, [0,255,0], 15)\n",
    "    cv2.polylines(new_image, np.int32([pts_right]), 0, [0,255,0], 15)\n",
    "\n",
    "def get_image_of_found_lane(binary_warped, max_y, visualize=False):\n",
    "    \"\"\"\n",
    "    Finds lane lines in an existing binary image and returns a new image with lane lines overlaid on top\n",
    "    \"\"\"\n",
    "    find_and_update_lane_lines(binary_warped, left_line, right_line, visualize)\n",
    "\n",
    "    warped_three_channel = make_3_channel_image_from_binary_channel(binary_warped)    \n",
    "    new_image = np.zeros_like(warped_three_channel)\n",
    "\n",
    "    draw_lane_on_image(new_image, left_line, right_line)\n",
    "    return new_image\n",
    "\n",
    "def find_and_update_lane_lines(binary_warped, left_line, right_line, visualize=False):\n",
    "    \"\"\"\n",
    "    Finds lane lines in a binary image and updates their representations\n",
    "    \"\"\"\n",
    "    if left_line.detected == True and right_line.detected == True:\n",
    "        # If left and right lanes were detected previously, then use those previous detections\n",
    "        # to find the updated lane lines\n",
    "        leftx, lefty, rightx, righty = find_lane_from_prior(\n",
    "            binary_warped,\n",
    "            left_line.average_fit,\n",
    "            right_line.average_fit,\n",
    "            visualize\n",
    "        )\n",
    "    else:\n",
    "        # If either of the lane lines wasn't detected previously, then perform a new sliding window search\n",
    "        leftx, lefty, rightx, righty = find_lane_sliding_windows(binary_warped, visualize)\n",
    "\n",
    "    left_line.update_line(lefty, leftx)\n",
    "    right_line.update_line(righty, rightx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for finding lane lines via sliding windows or within a margin of the previous detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_from_prior(binary_warped, left_fit, right_fit, visualize=False):\n",
    "    \"\"\"\n",
    "    Find lane line pixels using an existing polynomial as the starting point for the search.\n",
    "    \"\"\"\n",
    "    margin = 50\n",
    "\n",
    "    # get the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy, nonzerox = nonzero\n",
    "    \n",
    "    left_lane_inds = get_pixels_from_prior(nonzero, left_fit, margin, binary_warped.shape[0])\n",
    "    right_lane_inds = get_pixels_from_prior(nonzero, right_fit, margin, binary_warped.shape[0])\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty\n",
    "\n",
    "def find_lane_sliding_windows(binary_warped, visualize=False):\n",
    "    \"\"\"\n",
    "    Find lane line pixels using the sliding window technique\n",
    "    \"\"\"\n",
    "    img_height = binary_warped.shape[0]\n",
    "\n",
    "#     num_windows = 7\n",
    "    num_windows = 6\n",
    "    margin = 150\n",
    "    minpix = 100\n",
    "\n",
    "    # get the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy, nonzerox = nonzero\n",
    "\n",
    "    histogram = np.sum(binary_warped[img_height // 2:,:], axis=0)\n",
    "    out_img = make_3_channel_image_from_binary_channel(binary_warped)\n",
    "\n",
    "    # find midpoint of histogram\n",
    "    midpoint = np.int(histogram.shape[0] // 2)\n",
    "    # take midpoint of left and right sides as the start location for the search\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    window_height = np.int(img_height // num_windows)\n",
    "\n",
    "    # some initial values for the search\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    for window in range(num_windows):\n",
    "        win_y_low = img_height - (window + 1) * window_height\n",
    "        win_y_high = img_height - window * window_height\n",
    "\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        if visualize is True:\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "            (win_xleft_high,win_y_high),(255,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "            (win_xright_high,win_y_high),(255,255,0), 2) \n",
    "        \n",
    "        good_left_inds = get_pixels_in_window(nonzero, (win_xleft_low, win_xleft_high, win_y_low, win_y_high))\n",
    "        good_right_inds = get_pixels_in_window(nonzero, (win_xright_low, win_xright_high, win_y_low, win_y_high))\n",
    "\n",
    "        if len(good_left_inds) > 0:\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "        if len(good_right_inds) > 0:\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    if len(left_lane_inds) > 0:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    if len(right_lane_inds) > 0:\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    if visualize is True:\n",
    "        plot_image(out_img)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel(img, sobel_kernel, mag_thresh=(0, 255), dir_thresh=(0, np.pi/2)):\n",
    "    \"\"\"\n",
    "    Sobel filter for both magnitude and direction; return both separately so we can visualize them\n",
    "    \"\"\"\n",
    "    mag_thresh_min, mag_thresh_max = mag_thresh\n",
    "    dir_thresh_min, dir_thresh_max = dir_thresh\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "\n",
    "    # magnitude sobel\n",
    "    abs_sobel_xy = np.sqrt(abs_sobel_x ** 2 + abs_sobel_y ** 2)\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel_xy / np.max(abs_sobel_xy))\n",
    "\n",
    "    # directional sobel\n",
    "    sobel_dir = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "\n",
    "    output_mag = np.zeros_like(scaled_sobel)\n",
    "    output_mag[\n",
    "        (scaled_sobel >= mag_thresh_min) &\n",
    "        (scaled_sobel <= mag_thresh_max)\n",
    "    ] = 1\n",
    "\n",
    "    output_dir = np.zeros_like(scaled_sobel)\n",
    "    output_dir[\n",
    "        (sobel_dir >= dir_thresh_min) &\n",
    "        (sobel_dir <= dir_thresh_max)\n",
    "    ] = 1\n",
    "\n",
    "    return output_mag, output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(img, debug=False):\n",
    "    \"\"\"\n",
    "    Find edges in an image using these main techniques:\n",
    "    1) Extract white/yellow pixels\n",
    "    2) Extract directional / magnitude gradients via the Sobel operator\n",
    "    3) Bitwise AND for Sobel gradients (direction/magnitude)\n",
    "    4) Bitwise OR of white/yellow pixel masks together with the Sobel gradients\n",
    "       to fill in whatever pixels Sobel missed\n",
    "    \"\"\"\n",
    "    img = np.copy(img)\n",
    "\n",
    "\n",
    "    yellow_h_thresh = (12, 33)\n",
    "    yellow_s_thresh = (50, 255)\n",
    "    yellow_v_thresh = (75, 255)\n",
    "    white_h_thresh = (0, 179)\n",
    "    white_s_thresh = (0, 25)\n",
    "    white_v_thresh = (190, 255)\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    h = hsv[:,:,0]\n",
    "    s = hsv[:,:,1]\n",
    "    v = hsv[:,:,2]\n",
    "\n",
    "    # threshold color channels to capture yellow\n",
    "    h_binary = np.zeros_like(h)\n",
    "    s_binary = np.zeros_like(s)\n",
    "    v_binary = np.zeros_like(v)\n",
    "    h_binary[(h >= yellow_h_thresh[0]) & (h <= yellow_h_thresh[1])] = 1\n",
    "    s_binary[(s >= yellow_s_thresh[0]) & (s <= yellow_s_thresh[1])] = 1\n",
    "    v_binary[(v >= yellow_v_thresh[0]) & (v <= yellow_v_thresh[1])] = 1\n",
    "    yellow_binary = h_binary & s_binary & v_binary\n",
    "    \n",
    "    # threshold color channels to capture white\n",
    "    h_binary = np.zeros_like(h)\n",
    "    s_binary = np.zeros_like(s)\n",
    "    v_binary = np.zeros_like(v)\n",
    "    h_binary[(h >= white_h_thresh[0]) & (h <= white_h_thresh[1])] = 1\n",
    "    s_binary[(s >= white_s_thresh[0]) & (s <= white_s_thresh[1])] = 1\n",
    "    v_binary[(v >= white_v_thresh[0]) & (v <= white_v_thresh[1])] = 1\n",
    "    white_binary = h_binary & s_binary & v_binary\n",
    "\n",
    "    \n",
    "    dir_thresh = (0.7, 1.2)\n",
    "    mag_thresh = (70, 130)\n",
    "    sobel_mag, sobel_dir = sobel(img, sobel_kernel=9, mag_thresh=mag_thresh, dir_thresh=dir_thresh)\n",
    "\n",
    "    result = white_binary | yellow_binary | (sobel_mag & sobel_dir)\n",
    "\n",
    "    if debug is True:\n",
    "        plot_image(yellow_binary)\n",
    "        plot_image(white_binary)\n",
    "        plot_image(sobel_mag)\n",
    "        plot_image(sobel_dir)\n",
    "        plot_image(result)\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Line class that keeps track of our line detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    # class var to tune averaging\n",
    "    num_frames_to_average = 4\n",
    "\n",
    "    def __init__(self, max_x, max_y, ym_per_pix, xm_per_pix):\n",
    "        self.max_x = max_x\n",
    "        self.max_y = max_y\n",
    "        self.best_y = np.linspace(0, self.max_y - 1, self.max_y)\n",
    "        self.best_x = []\n",
    "        self.ym_per_pix = ym_per_pix\n",
    "        self.xm_per_pix = xm_per_pix\n",
    "\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.all_fits = []  \n",
    "        self.all_fits_world = []\n",
    "        self.average_fit = []\n",
    "        self.average_fit_world = []\n",
    "\n",
    "        # radius of curvature of the line in some units\n",
    "        self.average_curvature = None \n",
    "        self.all_curvature_values = []\n",
    "\n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.offset_world = 0\n",
    "\n",
    "    def get_curvature(self, average_fit, y, ym_per_pix):\n",
    "        a, b, c = average_fit\n",
    "        return ((1 + (2 * a * y * ym_per_pix + b) ** 2) ** 1.5) / abs(2 * a)\n",
    "        \n",
    "    def update_line(self, laney, lanex):\n",
    "        \n",
    "        coefficients = np.polyfit(laney, lanex, 2) if len(lanex) > 0 and len(laney) > 0 else []\n",
    "        coefficients_world = np.polyfit(laney * self.ym_per_pix, lanex * self.xm_per_pix, 2) if len(lanex) > 0 and len(laney) > 0 else []\n",
    "       \n",
    "        if len(self.average_fit) == 0:\n",
    "            self.average_fit = coefficients\n",
    "            self.average_fit_world = coefficients_world\n",
    "\n",
    "        if len(coefficients) > 0:\n",
    "            self.detected = True\n",
    "            self.all_fits.append(coefficients)\n",
    "            self.all_fits_world.append(coefficients_world)\n",
    "            self.all_curvature_values.append(self.get_curvature(self.average_fit_world, self.max_y - 1, self.ym_per_pix))\n",
    "        else:\n",
    "            self.detected = False\n",
    "\n",
    "        if len(self.all_fits) > self.num_frames_to_average:\n",
    "            self.all_fits.pop(0)\n",
    "            self.all_fits_world.pop(0)\n",
    "            self.all_curvature_values.pop(0)\n",
    "\n",
    "        self.average_fit = np.sum(self.all_fits, axis=0) / len(self.all_fits)\n",
    "        self.average_fit_world = np.sum(self.all_fits_world, axis=0) / len(self.all_fits_world) if len(self.all_fits_world) else 0\n",
    "        self.average_curvature = sum(self.all_curvature_values) / len(self.all_curvature_values) if len(self.all_curvature_values) else 0\n",
    "\n",
    "        if hasattr(self.average_fit, \"__len__\"):\n",
    "            self.best_x = get_x_from_poly(self.average_fit, self.best_y)\n",
    "\n",
    "    def get_x_and_y(self):\n",
    "        return self.best_x, self.best_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_detections():\n",
    "    \"\"\"\n",
    "    Resets previously instantiated left and right Line instances\n",
    "    \"\"\"\n",
    "    global left_line\n",
    "    global right_line\n",
    "\n",
    "    left_line = Line(img_width, img_height, ym_per_pix, xm_per_pix)\n",
    "    right_line = Line(img_width, img_height, ym_per_pix, xm_per_pix)\n",
    "\n",
    "def calibrate_for_main_video():\n",
    "    \"\"\"\n",
    "    Sets up transformation matrices for the main video\n",
    "    \"\"\"\n",
    "    global src\n",
    "    global dst\n",
    "    global M\n",
    "    global M_inv\n",
    "    reset_detections()\n",
    "\n",
    "    # top of the trapezoid\n",
    "    img_transform_min_y = 450\n",
    "    # offset from the center of the image\n",
    "    img_transform_top_center_offset = 49\n",
    "    # offset from the side of the image\n",
    "    img_transform_bottom_side_offset = 150\n",
    "\n",
    "    src = np.float32([\n",
    "        [img_transform_bottom_side_offset, img_height],\n",
    "        [img_width / 2 - img_transform_top_center_offset, img_transform_min_y],\n",
    "        [img_width / 2 + img_transform_top_center_offset, img_transform_min_y],\n",
    "        [img_width - img_transform_bottom_side_offset, img_height]\n",
    "    ])\n",
    "    dst = np.float32([\n",
    "        [300, img_height],\n",
    "        [300, 0],\n",
    "        [img_width - 300, 0],\n",
    "        [img_width - 300, img_height]\n",
    "    ])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "def calibrate_for_challenge():\n",
    "    \"\"\"\n",
    "    Sets up transformation matrices for the challenge video\n",
    "    \"\"\"\n",
    "    global src\n",
    "    global dst\n",
    "    global M\n",
    "    global M_inv\n",
    "\n",
    "    reset_detections()\n",
    "    # top of the trapezoid\n",
    "    # the perspective of this video seems to be higher up so we want to adjust the transform accordingly\n",
    "    img_transform_min_y = 470\n",
    "    # offset from the center of the image\n",
    "    img_transform_top_center_offset = 45\n",
    "    # offset from the side of the image\n",
    "    img_transform_bottom_side_offset = 230\n",
    "\n",
    "    src = np.float32([\n",
    "        [img_transform_bottom_side_offset, img_height],\n",
    "        [img_width / 2 - img_transform_top_center_offset, img_transform_min_y],\n",
    "        [img_width / 2 + img_transform_top_center_offset, img_transform_min_y],\n",
    "        [img_width - img_transform_bottom_side_offset, img_height]\n",
    "    ])\n",
    "    dst = np.float32([\n",
    "        [300, img_height],\n",
    "        [300, 0],\n",
    "        [img_width - 300, 0],\n",
    "        [img_width - 300, img_height]\n",
    "    ])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_height, img_width = target_dimensions\n",
    "lane_width = 3.66\n",
    "# placeholder values\n",
    "# meters per pixel in y dimension\n",
    "# estimated by using average length of and distance between white lane dashes (total of ~125 feet covered)\n",
    "ym_per_pix = 38.1 / 720\n",
    "\n",
    "# meters per pixel in the x direction;\n",
    "# estimated from average lane width (~12 feet) and the number of pixels\n",
    "# between the lane lines at the bottom of the screen (assume y=720 is directly below the camera)\n",
    "xm_per_pix = lane_width / 620\n",
    "\n",
    "# top of the trapezoid\n",
    "img_transform_min_y = 450\n",
    "# offset from the center of the image\n",
    "img_transform_top_center_offset = 49\n",
    "# offset from the side of the image\n",
    "img_transform_bottom_side_offset = 150\n",
    "\n",
    "src = np.float32([\n",
    "    [img_transform_bottom_side_offset, img_height],\n",
    "    [img_width / 2 - img_transform_top_center_offset, img_transform_min_y],\n",
    "    [img_width / 2 + img_transform_top_center_offset, img_transform_min_y],\n",
    "    [img_width - img_transform_bottom_side_offset, img_height]\n",
    "])\n",
    "dst = np.float32([\n",
    "    [300, img_height],\n",
    "    [300, 0],\n",
    "    [img_width - 300, 0],\n",
    "    [img_width - 300, img_height]\n",
    "])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "# a somewhat straight line is something with a radius curvature radius of greater than 10km\n",
    "somewhat_straight_curvature_radius = 5000\n",
    "min_non_centered_offset = 0.01\n",
    "\n",
    "# instantiate variables\n",
    "left_line = Line(img_width, img_height, ym_per_pix, xm_per_pix)\n",
    "right_line = Line(img_width, img_height, ym_per_pix, xm_per_pix)\n",
    "\n",
    "def format_in_meters(some_num):\n",
    "    \"\"\"\n",
    "    Takes a number of meters and rounds to 4 digits after the decimal.\n",
    "    If the number is less than 1 meter, then output as centimeters with 2 digits after the decimal.\n",
    "    \"\"\"\n",
    "    rounded = round(some_num, 4)\n",
    "    if rounded < 1:\n",
    "        rounded *= 100\n",
    "        unit = 'cm'\n",
    "    else:\n",
    "        unit = 'm'\n",
    "    return str(rounded) + unit\n",
    "\n",
    "def get_world_offset(left_line, right_line):\n",
    "    \"\"\"\n",
    "    Given 2 Line instances (left line, right line), output the camera car's offset relative to them.\n",
    "    This assumes the camera is perfectly centered on the camera car.\n",
    "    \"\"\"\n",
    "    best_x_left, best_y_left = left_line.get_x_and_y()\n",
    "    best_x_right, best_y_right = right_line.get_x_and_y()\n",
    "    if len(best_x_left) is 0 or len(best_x_right) is 0:\n",
    "        return 'unknown'\n",
    "    width_of_lane_on_screen = best_x_right[-1] - best_x_left[-1]\n",
    "    distance_from_center = best_x_right[-1] - width_of_lane_on_screen / 2 - img_width / 2\n",
    "    return distance_from_center * xm_per_pix\n",
    "    \n",
    "def get_lane_curvature(left_line, right_line):\n",
    "    \"\"\"\n",
    "    Given 2 Line instances (left line, right line), output their average curvature\n",
    "    \"\"\"\n",
    "    return (left_line.average_curvature + right_line.average_curvature) / 2\n",
    "    \n",
    "def annotate_image(img, left_line, right_line):\n",
    "    \"\"\"\n",
    "    Given an image and 2 Line instances, this composites lane curvature and offset metrics onto the image\n",
    "    \"\"\"\n",
    "    curvature = get_lane_curvature(left_line, right_line)\n",
    "    offset = get_world_offset(left_line, right_line)\n",
    "        \n",
    "    # if the radius of the curve is below a certain threshold, then we'll call it moving straight\n",
    "    if curvature < somewhat_straight_curvature_radius:\n",
    "        curvature_string = format_in_meters(curvature)\n",
    "    else:\n",
    "        curvature_string = 'straight line-ish'\n",
    "\n",
    "    # offset logic    \n",
    "    if offset is 'unknown':\n",
    "        offset_string = offset\n",
    "    elif abs(offset) < min_non_centered_offset:\n",
    "        # if the offset is less than 1cm, we'll say the car is centered\n",
    "        offset_string = 'centered-ish'        \n",
    "    elif offset < 0:\n",
    "        offset_string = format_in_meters(abs(offset)) + ' right'\n",
    "    else:\n",
    "        offset_string = format_in_meters(abs(offset)) + ' left'\n",
    "\n",
    "    cv2.putText(img, 'curvature: ' + curvature_string, (25, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(img, 'offset: ' + offset_string, (25, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    \n",
    "def process_video(input_filename, output_filename, subclip_range=None):\n",
    "    \"\"\"\n",
    "    Generic method to process an input video and output it to output_filename\n",
    "    The caller can optionally specify a subclip range (e.g. for debug purposes)\n",
    "    \"\"\"\n",
    "    clip = VideoFileClip(input_filename)\n",
    "    if subclip_range is not None:\n",
    "        start_time, end_time = subclip_range\n",
    "        clip = clip.subclip(start_time, end_time)\n",
    "    clip_output = clip.fl_image(process_image)\n",
    "    %time clip_output.write_videofile(output_filename, audio=False)\n",
    "\n",
    "def process_image(img, debug=False):\n",
    "    \"\"\"\n",
    "    Complete method for taking an image of the road, transforming and finding lane lines on it,\n",
    "    and outputting a final image with the lane lines and curvature/offset metrics.\n",
    "    \"\"\"\n",
    "    img_height, img_width, num_channels = img.shape\n",
    "\n",
    "    # step 1: undistort using previously determined values\n",
    "    undistorted = cv2.undistort(img, mtx, dist, None)\n",
    "\n",
    "    if debug is True:\n",
    "        plot_image(undistorted)\n",
    "\n",
    "    # step 2: find some edges in the untransformed image\n",
    "    edges = find_edges(undistorted, debug)\n",
    "\n",
    "    # step 3: transform edges image using a pre-computed transform\n",
    "    warped = cv2.warpPerspective(edges, M, (img_width, img_height), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # step 4: create an image of the detected lane\n",
    "    image_of_lane = get_image_of_found_lane(warped, img_height, debug)\n",
    "\n",
    "    # step 5: unwarp image of the lane\n",
    "    unwarped_lane = cv2.warpPerspective(image_of_lane, M_inv, (img_width, img_height), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # step 6: composite the unwarped lane image back onto the original image\n",
    "    weighted_final = weighted_img(undistorted, unwarped_lane, 1, 0.5)\n",
    "    \n",
    "    # step 7: compute and add annotations for curvature and offset to the final image\n",
    "    annotate_image(weighted_final, left_line, right_line)\n",
    "    \n",
    "    if debug is True:\n",
    "        plot_image(weighted_final)\n",
    "\n",
    "    return weighted_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_final.mp4\n",
      "[MoviePy] Writing video project_video_final.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [24:22<00:01,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_final.mp4 \n",
      "\n",
      "CPU times: user 35min 4s, sys: 1min 14s, total: 36min 19s\n",
      "Wall time: 24min 22s\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "def debug_image(filename):\n",
    "    reset_detections()\n",
    "    process_image(mpimg.imread(filename), True)\n",
    "    \n",
    "def process_challenge_video():\n",
    "    \"\"\"\n",
    "    Half-baked attempt at getting the challenge working\n",
    "    \"\"\"\n",
    "    calibrate_for_challenge()\n",
    "    process_video('challenge_video.mp4', 'challenge_video_with_lines.mp4')\n",
    "\n",
    "def process_main_video():\n",
    "    \"\"\"\n",
    "    Process the main video\n",
    "    \"\"\"\n",
    "    calibrate_for_main_video()\n",
    "    process_video('project_video_source.mp4', 'project_video_final.mp4')\n",
    "#     process_video('project_video.mp4', 'project_video_with_lines_20_to_25.mp4', (20, 25))\n",
    "#     process_video('project_video.mp4', 'project_video_with_lines_38_to_42.mp4', (38, 42))\n",
    "\n",
    "\n",
    "process_main_video()\n",
    "# process_challenge_video()\n",
    "\n",
    "# a bunch of test code below\n",
    "\n",
    "# calibrate_for_main_video()\n",
    "# debug_image('test_images/test1.jpg')\n",
    "# debug_image('test_images/test2.jpg')\n",
    "# debug_image('test_images/test3.jpg')\n",
    "# debug_image('test_images/test4.jpg')\n",
    "# debug_image('test_images/test5.jpg')\n",
    "# debug_image('test_images/test6.jpg')\n",
    "# debug_image('test_images/test7.jpg')\n",
    "# debug_image('test_images/test8.jpg')\n",
    "# debug_image('test_images/test9.jpg')\n",
    "# debug_image('test_images/straight_lines1.jpg')\n",
    "# debug_image('test_images/straight_lines2.jpg')\n",
    "# debug_image('test_images/color-shadow-example.jpg')\n",
    "# calibrate_for_challenge()\n",
    "# debug_image('test_images/challenge_test1.jpg')\n",
    "# debug_image('test_images/challenge_test2.jpg')\n",
    "# debug_image('test_images/challenge_test3.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
